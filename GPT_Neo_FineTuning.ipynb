{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "pUr_0Kt1JO3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDQep7ZXlRel",
        "outputId": "5de2d92a-f1a1-4384-985e-3c76d932744b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading textdata, 157697 bytes compressed\n",
            "[==================================================] 157697 bytes downloaded\n",
            "Downloaded and uncompressed: textdata\n",
            "Downloading emb-data, 187856 bytes compressed\n",
            "[==================================================] 187856 bytes downloaded\n",
            "Downloaded and uncompressed: emb-data\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'textdata:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5222373%2F8706391%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240626%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240626T144050Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D49545e99a0c753820caea68b4110044f75c40fcacd72c4ce4c1a8e8417b3e1098d27fad40feaabc972d29512f17f801a26ee0ad11ab1f6caa19451714418f157cd62ae6520e76a2954f699435ebcc6959a72ae694c0cc7453bc8aca915a6798d94e5685abb2979e28601195048f13ae24a43d4b5165a9475da3dccd9729026bc719deed77876d074eb5d5477bdb2cc79343882fd0acce4245def7cd38998e680eb3044d7947449cef221a13751b4f0104c6f5f46d19f18ecf4492f5e7d0dd5120647223ba5cd468132d77bb9dd5db7d8bd7d20e38469cb5787a9587718305671de509fd84d5655a44bc4d1c5c7449ee847f29d5180486ead04dd1c3137adc18d,emb-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5273960%2F8775105%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240626%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240626T144050Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8675ec24a72412a0b54b712a868fdf5f397fdb25b820f7f928525d62cbe6662ab20b4406eba95c36e416edc36084eed2ec488fcf8c7961bcccb203dee1701d246acc1fe91d820ac5521cc94d71fa3b3729637fad43e0602e10546e2636323718ede28956a84e6ffcdb9e7a17c10ac38076b8aee2aa24a715b8dd8512a001b2e08797dd98ed70541083e78b4a299503c398cda8b95a4c7ca3d8590656778d95f1ea74ce0a41caa924a8f38c9017e0e63e43ab121ad0b59b7fb6eaf8c7406ade32b5f68eb221137133f4845d697699ee30eb0bd9b7e525d3c50969a2fe291c5681ed73c15d73eb52bf9b1187f4d06f9332d6bbb61c7fe0167435061d718c0aaa0b'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XYyYAOvQlReq"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "#Suspend printing to stdout\n",
        "import sys\n",
        "import os\n",
        "original_stdout = sys.stdout\n",
        "\n",
        "# Redirect stdout to devnull\n",
        "sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "!pip install chromadb\n",
        "!pip install peft\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "# from langchain.llms import HuggingFaceHub\n",
        "import os\n",
        "from getpass import getpass\n",
        "# from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline,  Trainer, TrainingArguments, AdamW\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "# from chromadb import ChromaClient\n",
        "import chromadb\n",
        "import nltk\n",
        "import re\n",
        "import spacy\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import torch.multiprocessing as mp\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.distributed import init_process_group, destroy_process_group\n",
        "from transformers import MarianMTModel, MarianTokenizer, PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import random\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "from peft import get_peft_config, PeftType, LoraConfig ,get_peft_model,PeftModel, PeftConfig\n",
        "# from transformers import BitsAndBytesConfig\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "world_size = torch.cuda.device_count()\n",
        "# mp.spawn(<selfcontainedmethodforeachproc>, nprocs=world_size, args=(args,))\n",
        "# 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  Huggingface access token\n",
        "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass(\"HF Token:\")\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "sys.stdout = original_stdout  #Resume printing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aivNHNPo0Ry"
      },
      "source": [
        "# Loading Text , Model and Chroma DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384,
          "referenced_widgets": [
            "d07ad684e9f9479680d0f8609efd3bba",
            "15ad747e6abc4e05ba5e9478a9e8a66e",
            "81dfb18676ea4bd29a5e3a9cdf95fa26",
            "9f012e87a76c46d0bd8a3552705f81b1",
            "486452875c2446148fd23079a30a0a79",
            "0d3531c96a4e443fa1585850af7e198d",
            "d2579cf7eff64ef2abfa167e183b4d9f",
            "b9ad5c2104a842bb8b14cbf6fa7393e1",
            "ff14c71f09b343a2bddfd2923cdd4dcc",
            "55dd60a5a07b40519325fe2bb700a2d0",
            "e9a50cda947b404588f1e9683ee9cbb4",
            "e73b3f3b9ded43a594ae16332177de03",
            "319af381173245b89bc80e4edb974421",
            "694565562c1e44fd840190a37fd238a9",
            "0cf7bda1c12143f093cd9a526ef0f9dc",
            "d0bc7a16622f4677bac4b3a58a13359f",
            "b63e01602035456f9d3456aa76e90840",
            "0fde5656c3c446b78c6508df310f835f",
            "fc90514df66443668a442d4c435afb62",
            "992e088d407d424d8659bc90e0f6a479",
            "1b2b141c54394a978d472712ffcb4d1a",
            "1e0adb696af24c88b4649c453dfc67f8",
            "f0cecf8d7214450f8732f367e225d9d3",
            "84ded7d7a6b24f479d74db24cd153071",
            "421cba3f24dd4ea687dba1e6470d74dc",
            "991f782029a34a5f9d79bcaf7a3c6b58",
            "7b71b652c89542dfb6b32c6805e948fa",
            "eac243c806da424f8bc29fef4da3b016",
            "54c95eefff654508af6cc523824da38a",
            "c7d0aa6007c8438391d076a1ab09dfad",
            "2a87b64eaaac45d09db332316cae9337",
            "cb0eb35a408345c0ab0f93630f1d05a4",
            "ce73139f900e499baa53aeb95aa14ae9",
            "727d505aa50f4650ba528b6b2d030924",
            "98c01aa5e2734a6293c1620b133a3079",
            "641c441cf6d048288e64d29e1d98e576",
            "aefafa39816d4bd4b403c7c4a0a33776",
            "2dd60e1078db49188ce2d45ac91b56ab",
            "b847834cf4e846bd9441b7696b4ceb8b",
            "40c816edc7d84604a8567e676585a3d8",
            "8738fcf5dfb449f4873c3dd69d1effa0",
            "e7dde5254a4e46b8a3f7c93bd6ca30d6",
            "23ebc4e1a3a4471b8a90a7cde8c5b0f7",
            "9107e7d1d533438685c520a0fea728f2",
            "41f57a5e5d6d4b69a07308f0a71bb434",
            "0c513eff82024b7e8cc233c4f4a9a728",
            "eeff52966c624c5fbf9010ec6c65b88e",
            "7a060d581ca64ac79a00664e1e988e28",
            "98e8bc8a3a784509bfbfc84dd8ba67c6",
            "c3bb37827af746c5b36c724a84ba0e9b",
            "f0c6357e7de0432e804b626cf1a0b2f2",
            "47163b30d3354be296c77ef126f4c818",
            "e6b2390e1ff94995a25496388420c706",
            "a706b256232f4bd489e6d026f5f8048f",
            "8af9fbb6d5d64ee8adb3b44b4a6d8004",
            "1823c9a985cf44e891489c5ea921e384",
            "767ca123352d410bac4f03b9c69494f3",
            "0300766dc7b246c5856461d516dab05e",
            "58d89e0cb58147218c1f3d1878558d5d",
            "a882784ae28c4473a005c272c4159b8f",
            "7f4795033ab847fab0bb3fe7301b1ece",
            "a76d2860608542a18c267c27d9caf3bf",
            "4cf964a1ac0c44068a3143051c167057",
            "900b81f91d844e93bbe11b9d5d8dd1f1",
            "1a7d34779a7f4283908017bd23382572",
            "825c201777f14793952baf5507fe8691"
          ]
        },
        "id": "O4MxW-HZlRev",
        "outputId": "26c6f2e3-a2be-46d7-85f9-28b855fecb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d07ad684e9f9479680d0f8609efd3bba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e73b3f3b9ded43a594ae16332177de03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0cecf8d7214450f8732f367e225d9d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "727d505aa50f4650ba528b6b2d030924"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41f57a5e5d6d4b69a07308f0a71bb434"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1823c9a985cf44e891489c5ea921e384"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# model_id = \"EleutherAI/gpt-neo-2.7B\"\n",
        "# model_id = \"EleutherAI/gpt-neo-125m\"\n",
        "model_id = \"EleutherAI/gpt-neo-1.3B\"\n",
        "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "#DistilGPT-2 , T5-Small , GPT-2 small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKjV6QPelRey",
        "outputId": "4879030e-654f-481b-f1c5-5a0b654d7c97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1719564632750153775"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "with open('/kaggle/input/textdata/data0.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# client = chromadb.Client()\n",
        "# client.reset()\n",
        "client = chromadb.PersistentClient(path=\"/kaggle/working/chromadb\")\n",
        "# collection = client.get_collection(name=\"llm_lec_text\")\n",
        "\n",
        "# Create a collection for the LLM lectures\n",
        "collection = client.create_collection(name=\"llm_lec_text\")\n",
        "client.heartbeat() # returns a nanosecond heartbeat. Useful for making sure the client remains connected.\n",
        "# client.reset() # Empties and completely resets the database. ⚠️ This is destructive and not reversible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBfgyCxflRe0"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation\n",
        "\n",
        "# Define back translation function\n",
        "def back_translation(text, src_lang=\"en\", tgt_lang=\"de\"):\n",
        "    model_name = f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}'\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    translated = model.generate(**tokenizer(text, return_tensors=\"pt\", padding=True))\n",
        "    tgt_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "    model_name_back = f'Helsinki-NLP/opus-mt-{tgt_lang}-{src_lang}'\n",
        "    tokenizer_back = MarianTokenizer.from_pretrained(model_name_back)\n",
        "    model_back = MarianMTModel.from_pretrained(model_name_back)\n",
        "    translated_back = model_back.generate(**tokenizer_back(tgt_text, return_tensors=\"pt\", padding=True))\n",
        "    src_text_back = tokenizer_back.decode(translated_back[0], skip_special_tokens=True)\n",
        "\n",
        "    return src_text_back\n",
        "\n",
        "# Define paraphrasing function\n",
        "def paraphrase_text(text, model_name=\"tuner007/pegasus_paraphrase\"):\n",
        "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "    model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "    batch = tokenizer.prepare_seq2seq_batch([text], truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "    translated = model.generate(**batch)\n",
        "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
        "    return tgt_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH-AR2Qgy-YS"
      },
      "source": [
        "# Preprocessing Data , adding to the Chroma DB and converting into a Tensor Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "W72m8sI5lRe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedb478c-27b1-4254-ff41-72d328e81803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-1.3B')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "def clean_text(text):\n",
        "    # Remove unwanted characters and symbols\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\.\\s*', '. ', text)  # Ensure periods are followed by a single space\n",
        "    text = re.sub(r'\\s*\\.\\s*', '. ', text)  # Remove spaces before periods\n",
        "    return text.strip()\n",
        "\n",
        "# Function to tokenize sentences using SpaCy\n",
        "def spacyST(text):\n",
        "    doc = nlp(clean_text(text))\n",
        "    return [sent.text for sent in doc.sents]\n",
        "\n",
        "\n",
        "cleaned_text = re.sub(r'[\\\\\\[\\]{}@]', '', text)\n",
        "cleaned_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', cleaned_text)\n",
        "cleaned_text = cleaned_text.lower().strip()\n",
        "\n",
        "tokens = tokenizer.tokenize(cleaned_text)\n",
        "\n",
        "# 5. Chunk text\n",
        "max_length = 96\n",
        "chunks = []\n",
        "current_chunk = []\n",
        "for token in tokens:\n",
        "    current_chunk.append(token)\n",
        "    if len(current_chunk) >= max_length:\n",
        "        chunks.append(current_chunk)\n",
        "        current_chunk = []\n",
        "\n",
        "# Add the last chunk\n",
        "if current_chunk:\n",
        "    chunks.append(current_chunk)\n",
        "\n",
        "ips = []\n",
        "for chunk in chunks:\n",
        "    ips.append(tokenizer(chunk, return_tensors='pt', max_length=max_length, truncation=True, padding='max_length'))\n",
        "\n",
        "encodings = {\n",
        "    'input_ids': [],\n",
        "    'attention_mask': []\n",
        "}\n",
        "\n",
        "for ip in ips:\n",
        "    encodings['input_ids'].append(ip['input_ids'][0])\n",
        "    encodings['attention_mask'].append(ip['attention_mask'][0])\n",
        "\n",
        "# Convert lists to tensors\n",
        "encodings = {key: torch.stack(val) for key, val in encodings.items()}\n",
        "\n",
        "X = []\n",
        "for i in list(encodings.keys()):\n",
        "    X.append(encodings[i])\n",
        "XC = torch.cat((X[0].unsqueeze(dim=2),  X[1].unsqueeze(dim=2)),2)\n",
        "# print(XC.shape)\n",
        "\n",
        "\n",
        "inputIds = encodings['input_ids'].numpy().tolist()\n",
        "attMasks = encodings['attention_mask'].numpy().tolist()\n",
        "for ix in range(len(chunks)):\n",
        "    uniqueID = str(hash((\"-\").join(chunks[ix])))\n",
        "#     print(ix)\n",
        "    collection.add(ids=uniqueID,\n",
        "        documents=[(\"-\").join(chunks[ix])],\n",
        "        embeddings=inputIds[ix],\n",
        "        metadatas=[{'attention_mask': json.dumps(attMasks[ix])}])\n",
        "print('Done')\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        it = {key: tensor[idx] for key, tensor in self.encodings.items()}\n",
        "        it['labels'] = it['input_ids'].clone()\n",
        "        it['labels'][:-1] = it['input_ids'][1:]\n",
        "        it['labels'][-1] = -100  # Mask the first token\n",
        "        return it\n",
        "\n",
        "\n",
        "# dataT = torch.tensor(data.values)\n",
        "# dataC = dataT.reshape(4292,24,3)\n",
        "# dataset = torch.utils.data.Dataset(encodings)\n",
        "dataset = TextDataset(encodings)\n",
        "dataloader = DataLoader(dataset,\n",
        "                        batch_size=32,\n",
        "                        shuffle=True,\n",
        "#                         num_workers=2,\n",
        "#                        sampler=distDS,\n",
        "#                         drop_last=False,\n",
        "#                        pin_memory=True\n",
        "                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rusmZQsdlRe_"
      },
      "outputs": [],
      "source": [
        "#Saving Embedded data to CSV for easier loading\n",
        "\n",
        "# batch_size = 8\n",
        "# Y = XC.clone()\n",
        "# Y = Y[:,:,0]\n",
        "# # Y[:,1:] = Y[:,:-1]\n",
        "# Y[:,:-1] = Y[:,1:]\n",
        "# Y[:,-1] = -100\n",
        "# Y[:,0] = -100\n",
        "\n",
        "# XD = torch.cat((XC, Y.unsqueeze(dim=2)),2)\n",
        "# B,T,C = XD.shape\n",
        "# XD = XD.reshape(B*T, C)\n",
        "\n",
        "# XD = XD.numpy() #convert to Numpy array\n",
        "# XD = pd.DataFrame(XD) #convert to a dataframe\n",
        "# XD.to_csv(\"EmbData.csv\",index=False ) #save to file\n",
        "\n",
        "data = pd.read_csv('/kaggle/input/emb-data/EmbData(1).csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DS5VGCHzdGu"
      },
      "source": [
        "# TRAINING WITH PEFT LORA AND TRAINER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hEjYZLtwlRfC"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = Path('/kaggle/working/models')\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_NAME = 'gptNeoFT.pt'\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    inference_mode=False,\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "#     target_modules=['q', 'v'],\n",
        "#     target_modules=[\"query_key_value\"],\n",
        "#     target_modules=[\"transformer.h\"],\n",
        "    bias=\"none\",\n",
        ")\n",
        "# model.add_adapter(peft_config)\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p47y6Yya2epj",
        "outputId": "1ea8fcba-2b5e-487d-ad36-bcc878041054"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 6,291,456 || all params: 1,321,867,264 || trainable%: 0.4760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=7,\n",
        "    per_device_train_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "#     weight_decay=0.01,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=5,\n",
        "    logging_steps=200,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize the PeftTrainer\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "AOlxoDM4DEII",
        "outputId": "4cb05c69-0ffd-47a1-967f-71319f9070d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1939' max='1939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1939/1939 19:09, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.078200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.109700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.070200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.060700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.059800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.060300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.057200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.055900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1939, training_loss=0.48012721015965587, metrics={'train_runtime': 1151.5486, 'train_samples_per_second': 6.735, 'train_steps_per_second': 1.684, 'total_flos': 5426827093868544.0, 'train_loss': 0.48012721015965587, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzna0NLqzklo"
      },
      "source": [
        "# CUSTOM PYTORCH TRAINING LOOP WITH LAYER FREEZING, DATA PARALELISM , GRADIENT CLIPPING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "GtQm5W8SlRfE",
        "outputId": "0f63e18d-ea21-480a-ad53-67816ef6e9a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:   3%|▎         | 1/35 [00:11<06:47, 11.99s/it, loss=7.91]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-62b91896f28d>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m    972\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    837\u001b[0m                 )\n\u001b[1;32m    838\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    840\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB. GPU "
          ]
        }
      ],
      "source": [
        "dataset = torch.utils.data.TensorDataset(XC)\n",
        "dataloader = DataLoader(dataset,\n",
        "                        batch_size=32,\n",
        "                        shuffle=True,\n",
        "#                         num_workers=2,\n",
        "#                        sampler=distDS,\n",
        "#                         drop_last=False,\n",
        "#                        pin_memory=True\n",
        "                       )\n",
        "\n",
        "# Freeze the first 12 transformer layers\n",
        "for param in model.transformer.h[:16].parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Move the model to the device and set to bfloat16\n",
        "model = model.to(device).to(torch.bfloat16)\n",
        "# model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
        "model.train()\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=7e-3)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(101):\n",
        "    loop = tqdm(dataloader, leave=True)\n",
        "    for step, x in enumerate(loop):\n",
        "        input_ids = x[0][:,:, 0].to(device)\n",
        "        attention_mask = x[0][:,:, 1].to(device)\n",
        "        labels = x[0][:,:, 0].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "    if epoch%10 == 0:\n",
        "    # Save the model periodically\n",
        "        torch.save(model.state_dict(), f'{MODEL_PATH}/model_epoch_{epoch}.pt')\n",
        "        print(f'Model saved at epoch {epoch} ({datetime.datetime.now().timestamp()})')\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pF7qy_flRfF",
        "outputId": "7376952f-0900-48d5-df98-a520c3ed34ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid, fd = os.forkpty()\n"
          ]
        }
      ],
      "source": [
        "!rm /kaggle/working/models/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fKm87MXz-xU"
      },
      "source": [
        "DOWNLOAD SAVED WEIGHTS FROM KAGGLES DIRECTORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csQWNsOMlRfH",
        "outputId": "4518b435-709b-4518-d84a-3c323b18fc6b"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<a href='neoft125.zip' target='_blank'>neoft125.zip</a><br>",
            "text/plain": "/kaggle/working/neoft125.zip"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from IPython.display import FileLink, display\n",
        "\n",
        "def download_file(path, download_file_name):\n",
        "    os.chdir('/kaggle/working/')\n",
        "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
        "    command = f\"zip {zip_name} {path} -r\"\n",
        "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(\"Unable to run zip command!\")\n",
        "        print(result.stderr)\n",
        "        return\n",
        "    display(FileLink(f'{download_file_name}.zip'))\n",
        "download_file('/kaggle/working/models/model_epoch_100.pt', 'neoft125')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLBCrduklRfH"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Remove unwanted characters and symbols\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\.\\s*', '. ', text)  # Ensure periods are followed by a single space\n",
        "    text = re.sub(r'\\s*\\.\\s*', '. ', text)  # Remove spaces before periods\n",
        "    return text.strip()\n",
        "\n",
        "# Function to tokenize sentences using SpaCy\n",
        "def spacyST(text):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(clean_text(text))\n",
        "    return [sent.text for sent in doc.sents]\n",
        "\n",
        "def preproTxt(text):\n",
        "    sentText = spacyST(text)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    emb = tokenizer(sentText,padding=True,truncation=True, return_tensors='pt')\n",
        "    return emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U3p75osMlRfO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "9747aea9-b0bf-4215-c770-f4b3c7ce01bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b60eb69c81f2>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/working/output'\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# number of training epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length,...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1639\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_greater_or_equal_than_2_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"mlu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         \"\"\"\n\u001b[1;32m   2148\u001b[0m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m_setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   2056\u001b[0m                     \u001b[0;34mf\"Using the `Trainer` with `PyTorch` requires `accelerate>={ACCELERATE_MIN_VERSION}`: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m                     \u001b[0;34m\"Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "model = model.half()\n",
        "# model = model.to(torch.int8)\n",
        "# model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
        "\n",
        "dataset = TextDataset(encodings)\n",
        "dataloader = DataLoader(dataset,\n",
        "                        batch_size=32,\n",
        "                        shuffle=True,\n",
        "#                         num_workers=2,\n",
        "#                        sampler=distDS,\n",
        "#                         drop_last=False,\n",
        "#                        pin_memory=True\n",
        "                       )\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/kaggle/working/output',         # output directory\n",
        "    num_train_epochs=2,             # number of training epochs\n",
        "    per_device_train_batch_size=1,  # batch size for training\n",
        "    per_device_eval_batch_size=1,   # batch size for evaluation\n",
        "    warmup_steps=50,               # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,              # strength of weight decay\n",
        "    logging_dir='/kaggle/working/logs',           # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    gradient_accumulation_steps=1,               # accumulate gradients over 4 steps\n",
        "    fp16=True,                                   # enable mixed precision training\n",
        "    gradient_checkpointing=True,\n",
        "\n",
        "#     offload_state_dict=True,\n",
        "#     offload_optimizer=True,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=dataset,               # training dataset\n",
        "    tokenizer=tokenizer,                 # tokenizer\n",
        "#     use_cache=False,\n",
        "#     use_reentrant=False,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_huMXzprlRfQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Training attempt with sagemaker boto3\n",
        "!pip install sagemaker\n",
        "!pip install boto3\n",
        "\n",
        "import sagemaker\n",
        "import boto3\n",
        "from sagemaker.huggingface import HuggingFace\n",
        "\n",
        "try:\n",
        "\trole = sagemaker.get_execution_role()\n",
        "except ValueError:\n",
        "\tiam = boto3.client('iam')\n",
        "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
        "\n",
        "hyperparameters = {\n",
        "\t'model_name_or_path':'EleutherAI/gpt-neo-2.7B',\n",
        "\t'output_dir':'/opt/ml/model'\n",
        "\t# add your remaining hyperparameters\n",
        "\t# more info here https://github.com/huggingface/transformers/tree/v4.37.0/examples/pytorch/question-answering\n",
        "}\n",
        "\n",
        "# git configuration to download our fine-tuning script\n",
        "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.37.0'}\n",
        "\n",
        "# creates Hugging Face estimator\n",
        "huggingface_estimator = HuggingFace(\n",
        "\tentry_point='run_qa.py',\n",
        "\tsource_dir='./examples/pytorch/question-answering',\n",
        "\tinstance_type='ml.p3.2xlarge',\n",
        "\tinstance_count=1,\n",
        "\trole=role,\n",
        "\tgit_config=git_config,\n",
        "\ttransformers_version='4.37.0',\n",
        "\tpytorch_version='2.1.0',\n",
        "\tpy_version='py310',\n",
        "\thyperparameters = hyperparameters\n",
        ")\n",
        "\n",
        "# starting the train job\n",
        "huggingface_estimator.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING WITH MULTIPLE GPUS USING DISTRIBUTED DATA PARALLEL"
      ],
      "metadata": {
        "id": "8oCe5YNbIuF5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWmy8b8llRfZ"
      },
      "outputs": [],
      "source": [
        "def ddp_setup(rank: int, world_size: int):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    rank: Unique identifier of each process\n",
        "    world_size: Total number of processes\n",
        "    \"\"\"\n",
        "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
        "#     torch.cuda.set_device(rank)\n",
        "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
        "\n",
        "def cleanup():\n",
        "    destroy_process_group()\n",
        "\n",
        "\n",
        "def main(rank, world_size, model):\n",
        "        ddp_setup(rank,world_size)\n",
        "        dataloader = prepare(rank)\n",
        "        model = model.half()\n",
        "        model = model.cuda(rank)\n",
        "        model = DDP(model, device_ids=[rank], output_device=rank, find_unused_parameters=True)\n",
        "        model.train()\n",
        "        clip_value = 1.0\n",
        "        # Optimizer\n",
        "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "        accumulation_steps=16\n",
        "        print(\"Setup Complete\")\n",
        "        # Training loop\n",
        "        for epoch in range(10):  # number of epochs\n",
        "            dataloader.sampler.set_epoch(epoch)\n",
        "            loop = tqdm(dataloader, leave=True)\n",
        "            print(f\"Epoch Started : {epoch}\")\n",
        "            for step,batch in enumerate(loop):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "    #             input_ids =\n",
        "    #             attention_mask =\n",
        "    #             labels =\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        #         loss = outputs.loss.mean()\n",
        "                loss = outputs.loss / accumulation_steps\n",
        "        #         print(f'Loss: {loss}')\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "                if (step+1)%accumulation_steps == 0:\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "                loop.set_description(f'Epoch {epoch}')\n",
        "                loop.set_postfix(loss=loss.item())\n",
        "                torch.cuda.empty_cache()\n",
        "                print(f\"Epoch Ended : {epoch}\")\n",
        "        cleanup()\n",
        "        print(\"Training complete.\")\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnRHxU_ClRfa"
      },
      "outputs": [],
      "source": [
        "# batch_size = 32  # adjust as necessary\n",
        "# emb = None  # Initialize your embedding object\n",
        "\n",
        "# Determine number of GPUs available\n",
        "world_size = torch.cuda.device_count()\n",
        "\n",
        "for rank in range(world_size):\n",
        "    print(f\"Rank: {rank}\")\n",
        "    trained = main(rank, world_size, model)\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzFv7-WtlRfb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.utils.data import DataLoader, DistributedSampler\n",
        "from tqdm import tqdm\n",
        "from transformers import AdamW\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Kaggle environment setup\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
        "#     world_size = 2\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    world_size = torch.cuda.device_count()\n",
        "\n",
        "\n",
        "    def prepare(rank):\n",
        "        dataset = TextDataset(emb)\n",
        "        distDS = DistributedSampler(dataset=dataset, num_replicas=2, rank=rank, seed=42)\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            sampler=distDS,\n",
        "            drop_last=False,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "        return dataloader\n",
        "\n",
        "    def ddp_setup(rank: int, world_size: int):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        rank: Unique identifier of each process\n",
        "        world_size: Total number of processes\n",
        "        \"\"\"\n",
        "        torch.distributed.init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
        "\n",
        "    def cleanup():\n",
        "        dist.destroy_process_group()\n",
        "\n",
        "    def main(rank, world_size):\n",
        "        ddp_setup(rank, world_size)\n",
        "        dataloader = prepare(rank)\n",
        "        model = model.half()\n",
        "        model = model.cuda(rank)\n",
        "        model = DDP(model, device_ids=[rank], output_device=rank, find_unused_parameters=True)\n",
        "        model.train()\n",
        "        clip_value = 1.0\n",
        "        # Optimizer\n",
        "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "        accumulation_steps = 16\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(10):  # number of epochs\n",
        "            dataloader.sampler.set_epoch(epoch)\n",
        "            loop = tqdm(dataloader, leave=True)\n",
        "            for step, batch in enumerate(loop):\n",
        "                input_ids = batch['input_ids'].cuda(rank, non_blocking=True)\n",
        "                attention_mask = batch['attention_mask'].cuda(rank, non_blocking=True)\n",
        "                labels = batch['labels'].cuda(rank, non_blocking=True)\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss / accumulation_steps\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "                if (step + 1) % accumulation_steps == 0:\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "                loop.set_description(f'Epoch {epoch}')\n",
        "                loop.set_postfix(loss=loss.item())\n",
        "                torch.cuda.empty_cache()\n",
        "        cleanup()\n",
        "        print(\"Training complete.\")\n",
        "\n",
        "    mp.spawn(main, args=(world_size,), nprocs=world_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDCVk9xYlRfd"
      },
      "outputs": [],
      "source": [
        "# def getMax(Y):\n",
        "#   max = 0\n",
        "#   for i in Y:\n",
        "#     if max < len(i):\n",
        "#       max = len(i)\n",
        "#   return max\n",
        "\n",
        "# def padSeq(L, l, c):\n",
        "#   L1 = L[:]\n",
        "#   diff = l - len(L)\n",
        "#   if diff != 0:\n",
        "#     for i in range(diff):\n",
        "#       L1.append(c)\n",
        "#   return L1\n",
        "\n",
        "\n",
        "# #convert list to tensor\n",
        "# #pad y to max length present in the batch and convert to tensor , padd using the <End> token\n",
        "\n",
        "# def get_batch(X_train,y_train, X_test,y_test, batch_size,split=True):\n",
        "#   if split:\n",
        "#     dataX,dataY = X_train,y_train\n",
        "#   else:\n",
        "#    dataX, dataY = X_test,y_test\n",
        "#   ix = torch.randint(0,len(dataX),(batch_size,))\n",
        "#   x = torch.tensor([dataX[i] for i in ix]).to(device)\n",
        "#   y = [dataY[i] for i in ix]\n",
        "#   padL = getMax(y)\n",
        "#   y = torch.tensor([padSeq(i,getMax(y),str2int['<End>']) for i in y], dtype=torch.long, device=device)\n",
        "#   # y = torch.stack([data[i + 1: i + blk_size + 1] for i in ix]).to(device)\n",
        "#   return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ6fyGmilRfe"
      },
      "outputs": [],
      "source": [
        "maxC = 0\n",
        "maxI = 0\n",
        "for i in range(len(sentText)):\n",
        "    count = 0\n",
        "    for w in sentText[i].split():\n",
        "        count += 1\n",
        "    if count > maxC:\n",
        "        maxC = count\n",
        "        maxI = i\n",
        "maxC , maxI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nqJAGGclRff"
      },
      "outputs": [],
      "source": [
        "# tensor(15.1181) => tensor(14.2519)\n",
        "counts = []\n",
        "bigS = []\n",
        "for i in range(len(sentText)):\n",
        "    count = 0\n",
        "    for w in sentText[i].split():\n",
        "        count += 1\n",
        "    counts.append(count)\n",
        "    if count > 64:\n",
        "        bigS.append(i)\n",
        "counts = torch.tensor(counts,dtype=torch.float32)\n",
        "counts.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orCclMN4lRfm"
      },
      "outputs": [],
      "source": [
        "def padL(st, l):\n",
        "    L1 = st[:]\n",
        "    diff = l - len(st)\n",
        "    if diff != 0:\n",
        "        for i in range(diff):\n",
        "            L1+=\"<EOS>\"\n",
        "    return L1\n",
        "\n",
        "\n",
        "\n",
        "results = collection.query(\n",
        "    query_texts=padL(\"milestone model architectures\",64) # Chroma will embed this for you\n",
        "#     n_results=2 # how many results to return\n",
        ")\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0k8fc-HlRfn"
      },
      "outputs": [],
      "source": [
        "# # Example query function\n",
        "# def query_chroma(query_text):\n",
        "#     query_embedding = get_embeddings(query_text)\n",
        "#     results = collection.query(embedding=query_embedding, n_results=5)\n",
        "#     return results\n",
        "\n",
        "# # Example usage\n",
        "# query_results = query_chroma(\"milestone model architectures\")\n",
        "# for result in query_results['results']:\n",
        "#     print(result['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rp6msW7mJUcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESULTS"
      ],
      "metadata": {
        "id": "h_KRAkyTJXbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model.save_pretrained(\"./finalFT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKqqo26fJZYh",
        "outputId": "37f16a16-46a7-4afc-b5c6-17006aa70faa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_id = \"EleutherAI/gpt-neo-125m\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "peft_model_path = './finalFT'\n",
        "model = PeftModel.from_pretrained(model, peft_model_path).to(device)\n",
        "# modelOG = AutoModelForCausalLM.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "Wr-WmD3fJeDR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question, max_length=100):\n",
        "    input_text = f\"Question: {question}\\nAnswer:\"\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return answer.split(\"Answer:\")[-1].strip()\n",
        "\n",
        "generate_answer(input())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "Ph8Ps1uQJg9A",
        "outputId": "3ebcf8be-5c27-47d7-fa9a-a71283b293e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is CS324 ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A computer science course that is taught by a professor at the University of California, Santa Barbara.\\n\\nQuestion\\nWhat is the difference between a computer scientist and a software engineer?\\nAnswers:\\nA computer engineer is a person who designs and develops computer software. A software developer is someone who develops software for a specific purpose. Computer scientists are people who study computer programming. Software engineers are software developers who are involved in the development of software and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"EleutherAI/gpt-neo-1.3B\"\n",
        "modelOG = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
        "tokenizerOG = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "ABWgy4liJ4e_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question, max_length=100):\n",
        "    input_text = f\"Question: {question}\\nAnswer:\"\n",
        "    input_ids = tokenizerOG.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "    output = modelOG.generate(input_ids, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "    answer = tokenizerOG.decode(output[0], skip_special_tokens=True)\n",
        "    return answer.split(\"Answer:\")[-1].strip()\n",
        "generate_answer(input())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "VVk-Js_5JiHX",
        "outputId": "3990f868-d6f9-4d04-ea19-d693ac424db4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is CS324?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A Computer Sciences degree is an undergraduate degree in computer science. It is usually a two-year degree. The degree can be earned in a number of ways, including a bachelor's degree, a master's, or a doctorate. A computer scientist is someone who studies computer systems and computer programming. Computer science is one of the most popular undergraduate degrees\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "3St0MqNHJpam"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_kaK0EvKKCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5222373,
          "sourceId": 8706391,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5273960,
          "sourceId": 8775105,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30732,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d07ad684e9f9479680d0f8609efd3bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15ad747e6abc4e05ba5e9478a9e8a66e",
              "IPY_MODEL_81dfb18676ea4bd29a5e3a9cdf95fa26",
              "IPY_MODEL_9f012e87a76c46d0bd8a3552705f81b1"
            ],
            "layout": "IPY_MODEL_486452875c2446148fd23079a30a0a79"
          }
        },
        "15ad747e6abc4e05ba5e9478a9e8a66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3531c96a4e443fa1585850af7e198d",
            "placeholder": "​",
            "style": "IPY_MODEL_d2579cf7eff64ef2abfa167e183b4d9f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "81dfb18676ea4bd29a5e3a9cdf95fa26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ad5c2104a842bb8b14cbf6fa7393e1",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff14c71f09b343a2bddfd2923cdd4dcc",
            "value": 200
          }
        },
        "9f012e87a76c46d0bd8a3552705f81b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55dd60a5a07b40519325fe2bb700a2d0",
            "placeholder": "​",
            "style": "IPY_MODEL_e9a50cda947b404588f1e9683ee9cbb4",
            "value": " 200/200 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "486452875c2446148fd23079a30a0a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3531c96a4e443fa1585850af7e198d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2579cf7eff64ef2abfa167e183b4d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9ad5c2104a842bb8b14cbf6fa7393e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff14c71f09b343a2bddfd2923cdd4dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55dd60a5a07b40519325fe2bb700a2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a50cda947b404588f1e9683ee9cbb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e73b3f3b9ded43a594ae16332177de03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_319af381173245b89bc80e4edb974421",
              "IPY_MODEL_694565562c1e44fd840190a37fd238a9",
              "IPY_MODEL_0cf7bda1c12143f093cd9a526ef0f9dc"
            ],
            "layout": "IPY_MODEL_d0bc7a16622f4677bac4b3a58a13359f"
          }
        },
        "319af381173245b89bc80e4edb974421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b63e01602035456f9d3456aa76e90840",
            "placeholder": "​",
            "style": "IPY_MODEL_0fde5656c3c446b78c6508df310f835f",
            "value": "config.json: 100%"
          }
        },
        "694565562c1e44fd840190a37fd238a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc90514df66443668a442d4c435afb62",
            "max": 1347,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_992e088d407d424d8659bc90e0f6a479",
            "value": 1347
          }
        },
        "0cf7bda1c12143f093cd9a526ef0f9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2b141c54394a978d472712ffcb4d1a",
            "placeholder": "​",
            "style": "IPY_MODEL_1e0adb696af24c88b4649c453dfc67f8",
            "value": " 1.35k/1.35k [00:00&lt;00:00, 99.5kB/s]"
          }
        },
        "d0bc7a16622f4677bac4b3a58a13359f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b63e01602035456f9d3456aa76e90840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fde5656c3c446b78c6508df310f835f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc90514df66443668a442d4c435afb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992e088d407d424d8659bc90e0f6a479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b2b141c54394a978d472712ffcb4d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e0adb696af24c88b4649c453dfc67f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0cecf8d7214450f8732f367e225d9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84ded7d7a6b24f479d74db24cd153071",
              "IPY_MODEL_421cba3f24dd4ea687dba1e6470d74dc",
              "IPY_MODEL_991f782029a34a5f9d79bcaf7a3c6b58"
            ],
            "layout": "IPY_MODEL_7b71b652c89542dfb6b32c6805e948fa"
          }
        },
        "84ded7d7a6b24f479d74db24cd153071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eac243c806da424f8bc29fef4da3b016",
            "placeholder": "​",
            "style": "IPY_MODEL_54c95eefff654508af6cc523824da38a",
            "value": "vocab.json: 100%"
          }
        },
        "421cba3f24dd4ea687dba1e6470d74dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d0aa6007c8438391d076a1ab09dfad",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a87b64eaaac45d09db332316cae9337",
            "value": 798156
          }
        },
        "991f782029a34a5f9d79bcaf7a3c6b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0eb35a408345c0ab0f93630f1d05a4",
            "placeholder": "​",
            "style": "IPY_MODEL_ce73139f900e499baa53aeb95aa14ae9",
            "value": " 798k/798k [00:00&lt;00:00, 4.63MB/s]"
          }
        },
        "7b71b652c89542dfb6b32c6805e948fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac243c806da424f8bc29fef4da3b016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c95eefff654508af6cc523824da38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7d0aa6007c8438391d076a1ab09dfad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a87b64eaaac45d09db332316cae9337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb0eb35a408345c0ab0f93630f1d05a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce73139f900e499baa53aeb95aa14ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "727d505aa50f4650ba528b6b2d030924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98c01aa5e2734a6293c1620b133a3079",
              "IPY_MODEL_641c441cf6d048288e64d29e1d98e576",
              "IPY_MODEL_aefafa39816d4bd4b403c7c4a0a33776"
            ],
            "layout": "IPY_MODEL_2dd60e1078db49188ce2d45ac91b56ab"
          }
        },
        "98c01aa5e2734a6293c1620b133a3079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b847834cf4e846bd9441b7696b4ceb8b",
            "placeholder": "​",
            "style": "IPY_MODEL_40c816edc7d84604a8567e676585a3d8",
            "value": "merges.txt: 100%"
          }
        },
        "641c441cf6d048288e64d29e1d98e576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8738fcf5dfb449f4873c3dd69d1effa0",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7dde5254a4e46b8a3f7c93bd6ca30d6",
            "value": 456356
          }
        },
        "aefafa39816d4bd4b403c7c4a0a33776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ebc4e1a3a4471b8a90a7cde8c5b0f7",
            "placeholder": "​",
            "style": "IPY_MODEL_9107e7d1d533438685c520a0fea728f2",
            "value": " 456k/456k [00:00&lt;00:00, 1.84MB/s]"
          }
        },
        "2dd60e1078db49188ce2d45ac91b56ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b847834cf4e846bd9441b7696b4ceb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c816edc7d84604a8567e676585a3d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8738fcf5dfb449f4873c3dd69d1effa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7dde5254a4e46b8a3f7c93bd6ca30d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23ebc4e1a3a4471b8a90a7cde8c5b0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9107e7d1d533438685c520a0fea728f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41f57a5e5d6d4b69a07308f0a71bb434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c513eff82024b7e8cc233c4f4a9a728",
              "IPY_MODEL_eeff52966c624c5fbf9010ec6c65b88e",
              "IPY_MODEL_7a060d581ca64ac79a00664e1e988e28"
            ],
            "layout": "IPY_MODEL_98e8bc8a3a784509bfbfc84dd8ba67c6"
          }
        },
        "0c513eff82024b7e8cc233c4f4a9a728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3bb37827af746c5b36c724a84ba0e9b",
            "placeholder": "​",
            "style": "IPY_MODEL_f0c6357e7de0432e804b626cf1a0b2f2",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "eeff52966c624c5fbf9010ec6c65b88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47163b30d3354be296c77ef126f4c818",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6b2390e1ff94995a25496388420c706",
            "value": 90
          }
        },
        "7a060d581ca64ac79a00664e1e988e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a706b256232f4bd489e6d026f5f8048f",
            "placeholder": "​",
            "style": "IPY_MODEL_8af9fbb6d5d64ee8adb3b44b4a6d8004",
            "value": " 90.0/90.0 [00:00&lt;00:00, 6.15kB/s]"
          }
        },
        "98e8bc8a3a784509bfbfc84dd8ba67c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3bb37827af746c5b36c724a84ba0e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c6357e7de0432e804b626cf1a0b2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47163b30d3354be296c77ef126f4c818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b2390e1ff94995a25496388420c706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a706b256232f4bd489e6d026f5f8048f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af9fbb6d5d64ee8adb3b44b4a6d8004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1823c9a985cf44e891489c5ea921e384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_767ca123352d410bac4f03b9c69494f3",
              "IPY_MODEL_0300766dc7b246c5856461d516dab05e",
              "IPY_MODEL_58d89e0cb58147218c1f3d1878558d5d"
            ],
            "layout": "IPY_MODEL_a882784ae28c4473a005c272c4159b8f"
          }
        },
        "767ca123352d410bac4f03b9c69494f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f4795033ab847fab0bb3fe7301b1ece",
            "placeholder": "​",
            "style": "IPY_MODEL_a76d2860608542a18c267c27d9caf3bf",
            "value": "model.safetensors: 100%"
          }
        },
        "0300766dc7b246c5856461d516dab05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cf964a1ac0c44068a3143051c167057",
            "max": 5312673800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_900b81f91d844e93bbe11b9d5d8dd1f1",
            "value": 5312673800
          }
        },
        "58d89e0cb58147218c1f3d1878558d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7d34779a7f4283908017bd23382572",
            "placeholder": "​",
            "style": "IPY_MODEL_825c201777f14793952baf5507fe8691",
            "value": " 5.31G/5.31G [00:32&lt;00:00, 235MB/s]"
          }
        },
        "a882784ae28c4473a005c272c4159b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4795033ab847fab0bb3fe7301b1ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a76d2860608542a18c267c27d9caf3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf964a1ac0c44068a3143051c167057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "900b81f91d844e93bbe11b9d5d8dd1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a7d34779a7f4283908017bd23382572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "825c201777f14793952baf5507fe8691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}